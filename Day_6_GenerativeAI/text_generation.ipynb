{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "356e7f64-3e20-4131-821b-b6aa9315b02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\MinicondaEnvs\\ai_ml_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Error while downloading from https://huggingface.co/gpt2/resolve/main/model.safetensors: HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Device set to use cpu\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The future of Artificial Intelligence is a very exciting time indeed, as we can see from the recent development in the field of Artificial Intelligence, where we are witnessing the emergence of a set of new opportunities in which the most effective techniques are being used to enhance our lives and improve our quality of life.\n",
      "\n",
      "So, let's take a look at why we are seeing so many new possibilities in AI and the future of Artificial Intelligence.\n",
      "\n",
      "We are now entering a new era of Artificial Intelligence where our computers are at the forefront of research and development, and so it is with great pleasure to share with you some of the exciting developments that we are seeing in the field of Artificial Intelligence.\n",
      "\n",
      "In order to better understand the current state of Artificial Intelligence, we first need to look at how we can help the human brain and the mind. We need to think about how artificial intelligence is going to help us better understand our emotions, emotions, and behaviours. In short, we need to think about how our brain is going to help us better understand our emotions and behaviour.\n",
      "\n",
      "To begin with, we need to take a look at the way our brain works. As you can see from our graph below, our brain works by taking a look at the way the parts of the brain that are involved in emotion\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Use the 'pipeline' function for text generation\n",
    "# We'll use a pre-trained GPT-2 model, which is a good starting point\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "\n",
    "# Generate text from a prompt\n",
    "prompt = \"The future of Artificial Intelligence is\"\n",
    "result = generator(prompt, max_length=50, num_return_sequences=1)\n",
    "\n",
    "# Print the generated text\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139649cf-ee78-44bc-8087-08a5295986e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
