{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "356e7f64-3e20-4131-821b-b6aa9315b02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\MinicondaEnvs\\ai_ml_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use cpu\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The future of Artificial Intelligence is all about artificial intelligence, so it's time for AI to have a shot at winning the next race in the race to become the next supreme being.\n",
      "\n",
      "The next step for AI is a new paradigm for artificial intelligence which is to become a superintelligence that can do everything in the world and at the same time be able to do it at a very low cost.\n",
      "\n",
      "We hope that this book is a stepping stone to a more advanced version of AI, which would allow us to do things that are difficult to do with the current technology.\n",
      "\n",
      "What are some of the biggest challenges facing AI?\n",
      "\n",
      "The biggest challenge facing AI is how to make it very efficient.\n",
      "\n",
      "There are a number of problems that AI can't solve.\n",
      "\n",
      "The most obvious is that it cannot learn and remember anything.\n",
      "\n",
      "There are many ways to solve this problem.\n",
      "\n",
      "But there are also many ways to find the best solution to the problem.\n",
      "\n",
      "And yet, it's not easy.\n",
      "\n",
      "Even though we were able to solve the most difficult problem of AI, there is still a lot that is not covered.\n",
      "\n",
      "We need to learn how to learn, but there are so many other things that AI can't do which means that it doesn\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Use the 'pipeline' function for text generation\n",
    "# We'll use a pre-trained GPT-2 model, which is a good starting point\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "\n",
    "# Generate text from a prompt\n",
    "prompt = \"The future of Artificial Intelligence is\"\n",
    "result = generator(prompt, max_length=50, num_return_sequences=1)\n",
    "\n",
    "# Print the generated text\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "139649cf-ee78-44bc-8087-08a5295986e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=53) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: The acting was terrible, but the music was decent. Sentiment: Negative\n",
      "Review: I haven't seen a better plot twist in years! Sentiment: Positive\n",
      "Review: The runtime was too long. I was bored. Sentiment: Negative\n",
      "Review: This film should win all the awards. The cinematography is brilliant. Sentiment:Review: There wasn't any story. Sentiment: Negative\n",
      "Review: There were no plot twists in the story. Sentiment: Negative\n",
      "Reviewed: Overall I enjoyed this story. Sentiment: Positive\n",
      "Reviewed: Overall I loved this story. Sentiment: Negative\n"
     ]
    }
   ],
   "source": [
    "# few_shot_prompt = \"\"\"\n",
    "#     You are a sentiment analysis system. Your task is to classify the following movie reviews as 'positive' or 'negative'\n",
    "#     Examples:\n",
    "#     Review: The acting was terrible, but the music was decent.\n",
    "#     Sentiment: Negative\n",
    "#     Review: I haven't seen a better plot twist in years!\n",
    "#     Sentiment: Positive\n",
    "#     Review: The runtime was too long. I was bored.\n",
    "#     Sentiment: Negative\n",
    "\n",
    "#     Review: This film should win all the awards. The cinematography is brilliant.\n",
    "#     Sentiment: \n",
    "# \"\"\"\n",
    "\n",
    "# sentiment_result = generator(few_shot_prompt, max_length=200)\n",
    "# print(sentiment_result[0]['generated_text'])\n",
    "\n",
    "# 1. Define the concise prompt (fewer line breaks, no introductory sentence)\n",
    "fixed_prompt = \"\"\"Review: The acting was terrible, but the music was decent. Sentiment: Negative\n",
    "Review: I haven't seen a better plot twist in years! Sentiment: Positive\n",
    "Review: The runtime was too long. I was bored. Sentiment: Negative\n",
    "Review: This film should win all the awards. The cinematography is brilliant. Sentiment:\"\"\"\n",
    "\n",
    "# 2. Call the generator with a very small max_length to force it to stop\n",
    "fixed_sentiment_result = generator(fixed_prompt, max_length=len(fixed_prompt.split()) + 5)\n",
    "\n",
    "# 3. Print the result\n",
    "print(fixed_sentiment_result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "034094c4-828d-41f4-98b4-c978c1a87d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=200) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a creative name generator for businesses. Your task is to generate a list of five names for a coffee shop and give a brief explanation about each of them.\n",
      "\n",
      "What is the best part of working with businesses?\n",
      "\n",
      "You're not required to make any of this information public, but it is important to understand why you might want it.\n",
      "\n",
      "You should also consider your business's name. The more you learn about your company, the more likely you are to become familiar with its name.\n",
      "\n",
      "Think about the different business names that businesses use. What do you think makes it better, or worse, how do you know it's better? If you think about the business name, you may think that it's better than your existing business name.\n",
      "\n",
      "If you think about the business name, you may think that it's better than your existing business name. You should consider the length of time it takes to learn a new business name. Do you think it's worth trying this time to learn a new name?\n",
      "\n",
      "If you think about the length of time it takes to learn a new name? Do you think the name is interesting? Does the name make a difference in your business's life?\n",
      "\n",
      "If you think about the name, you may think that it's interesting? Does the name make a difference in your business's life? The job description of each business name should also be a key factor\n"
     ]
    }
   ],
   "source": [
    "zero_shot_prompt = \"\"\"You are a creative name generator for businesses. Your task is to generate a list of five names for a coffee shop and give a brief explanation about each of them\"\"\"\n",
    "\n",
    "names_list = generator(zero_shot_prompt, max_length=200)\n",
    "\n",
    "print(names_list[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5edecd33-a4ee-4eaa-b070-49f083730407",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=300) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: The original price of a shirt was $50. It was marked down by 20%. How much is the final price?\n",
      "Chain of Thought: First, calculate the discount amount: 20% of $50 is $0.20 * 50 = $10. Next, subtract the discount from the original price: $50 - $10 = $40.\n",
      "Answer: $40\n",
      "\n",
      "Question: There were 15 passengers on a bus. At the first stop, 6 got off and 3 got on. At the second stop, 4 got off and 2 got on. How many passengers are on the bus now?\n",
      "Chain of Thought: Let's think step by step.\n",
      "Answer:\n",
      "\n",
      "1. Take the last passenger off the bus (the one who got off) and replace them with another. 2. Line up the bus with a seat for each passenger. 3. Start with one passenger in the front row, then one in the back. 4. Line up the seats. 5. Line up each passenger as you go. 6. Now let's see how many passengers are on the bus now:\n",
      "\n",
      "1. 2. 3. 4.\n",
      "\n",
      "Question: The bus driver told me it was \"totally dead.\"\n",
      "\n",
      "Chain of Thought: He said it was \"nearly dead,\" but I still said it was \"much better.\"\n",
      "\n",
      "Answer:\n",
      "\n",
      "a. A car is dead.\n",
      "\n",
      "b. The driver of the car asked me if I had done a good job.\n",
      "\n",
      "c. It's just that I didn't pay attention to the fact that the driver of the car is dead.\n",
      "\n",
      "d. I've been getting calls from the police and asking about the passenger that died.\n",
      "\n",
      "Answer:\n",
      "\n",
      "d. He said they're getting \"serious questions.\"\n",
      "\n",
      "Question: I've been looking for the missing person since May.\n",
      "\n",
      "Chain of Thought:\n",
      "\n",
      "a. I\n"
     ]
    }
   ],
   "source": [
    "# --- Task 2: Implementing Chain-of-Thought (CoT) ---\n",
    "\n",
    "# 1. Define the Chain-of-Thought Prompt\n",
    "# This prompt uses one example to teach the model how to reason step-by-step.\n",
    "cot_prompt = \"\"\"\n",
    "Question: The original price of a shirt was $50. It was marked down by 20%. How much is the final price?\n",
    "Chain of Thought: First, calculate the discount amount: 20% of $50 is $0.20 * 50 = $10. Next, subtract the discount from the original price: $50 - $10 = $40.\n",
    "Answer: $40\n",
    "\n",
    "Question: There were 15 passengers on a bus. At the first stop, 6 got off and 3 got on. At the second stop, 4 got off and 2 got on. How many passengers are on the bus now?\n",
    "Chain of Thought: Let's think step by step.\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# 2. Call the generator with a sufficient max_length for the reasoning steps\n",
    "# We use 300 to ensure the model has enough tokens to write out all the steps.\n",
    "cot_result = generator(cot_prompt, max_length=300)\n",
    "\n",
    "# 3. Print the generated text cleanly\n",
    "print(cot_result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1e39a72-bfd6-4094-be39-eea1672086ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=200) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: There were 15 passengers on a bus. At the first stop, 6 got off and 3 got on. At the second stop, 4 got off and 2 got on. How many passengers are on the bus now? Let's think step by step.\n",
      "Answer: Lets think step by step and divide by 10, for the sake of comparison.\n",
      "Step 1: A bus is a train.\n",
      "Step 2: The train stops at the train station.\n",
      "Step 3: The train enters the station.\n",
      "Step 4: The train leaves. It's like walking through a garden.\n",
      "Step 5: The train arrives.\n",
      "Step 6: The train leaves.\n",
      "Step 7: The train exits.\n",
      "Step 8: The train enters the station. It's like walking through a garden.\n",
      "Step 9: The train exits.\n",
      "Step 10: The train comes back.\n",
      "Step 11: The train enters the station.\n",
      "Step 12: The train enters the main entrance. It's like walking through a garden.\n",
      "Step 13: The train goes to the main station.\n",
      "Step 14: The train enters.\n",
      "Step 15: The train arrives.\n",
      "Step 16: The train comes back.\n"
     ]
    }
   ],
   "source": [
    "zero_shot_cot = \"\"\"Question: There were 15 passengers on a bus. At the first stop, 6 got off and 3 got on. At the second stop, 4 got off and 2 got on. How many passengers are on the bus now? Let's think step by step.\n",
    "Answer: Lets think step by step\"\"\"\n",
    "\n",
    "zero_shot_cot_result = generator(zero_shot_cot, max_length=200)\n",
    "print(zero_shot_cot_result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc40e08-7805-466b-be4f-5429a9ccda1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
