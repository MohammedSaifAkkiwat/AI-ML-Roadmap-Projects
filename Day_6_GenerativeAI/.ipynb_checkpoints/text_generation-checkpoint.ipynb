{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356e7f64-3e20-4131-821b-b6aa9315b02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\MinicondaEnvs\\ai_ml_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use cpu\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Use the 'pipeline' function for text generation\n",
    "# We'll use a pre-trained GPT-2 model, which is a good starting point\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "\n",
    "# Generate text from a prompt\n",
    "prompt = \"The future of Artificial Intelligence is\"\n",
    "result = generator(prompt, max_length=50, num_return_sequences=1)\n",
    "\n",
    "# Print the generated text\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139649cf-ee78-44bc-8087-08a5295986e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# few_shot_prompt = \"\"\"\n",
    "#     You are a sentiment analysis system. Your task is to classify the following movie reviews as 'positive' or 'negative'\n",
    "#     Examples:\n",
    "#     Review: The acting was terrible, but the music was decent.\n",
    "#     Sentiment: Negative\n",
    "#     Review: I haven't seen a better plot twist in years!\n",
    "#     Sentiment: Positive\n",
    "#     Review: The runtime was too long. I was bored.\n",
    "#     Sentiment: Negative\n",
    "\n",
    "#     Review: This film should win all the awards. The cinematography is brilliant.\n",
    "#     Sentiment: \n",
    "# \"\"\"\n",
    "\n",
    "# sentiment_result = generator(few_shot_prompt, max_length=200)\n",
    "# print(sentiment_result[0]['generated_text'])\n",
    "\n",
    "# 1. Define the concise prompt (fewer line breaks, no introductory sentence)\n",
    "fixed_prompt = \"\"\"Review: The acting was terrible, but the music was decent. Sentiment: Negative\n",
    "Review: I haven't seen a better plot twist in years! Sentiment: Positive\n",
    "Review: The runtime was too long. I was bored. Sentiment: Negative\n",
    "Review: This film should win all the awards. The cinematography is brilliant. Sentiment:\"\"\"\n",
    "\n",
    "# 2. Call the generator with a very small max_length to force it to stop\n",
    "fixed_sentiment_result = generator(fixed_prompt, max_length=len(fixed_prompt.split()) + 5)\n",
    "\n",
    "# 3. Print the result\n",
    "print(fixed_sentiment_result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034094c4-828d-41f4-98b4-c978c1a87d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_prompt = \"\"\"You are a creative name generator for businesses. Your task is to generate a list of five names for a coffee shop and give a brief explanation about each of them\"\"\"\n",
    "\n",
    "names_list = generator(zero_shot_prompt, max_length=200)\n",
    "\n",
    "print(names_list[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edecd33-a4ee-4eaa-b070-49f083730407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Task 2: Implementing Chain-of-Thought (CoT) ---\n",
    "\n",
    "# 1. Define the Chain-of-Thought Prompt\n",
    "# This prompt uses one example to teach the model how to reason step-by-step.\n",
    "cot_prompt = \"\"\"\n",
    "Question: The original price of a shirt was $50. It was marked down by 20%. How much is the final price?\n",
    "Chain of Thought: First, calculate the discount amount: 20% of $50 is $0.20 * 50 = $10. Next, subtract the discount from the original price: $50 - $10 = $40.\n",
    "Answer: $40\n",
    "\n",
    "Question: There were 15 passengers on a bus. At the first stop, 6 got off and 3 got on. At the second stop, 4 got off and 2 got on. How many passengers are on the bus now?\n",
    "Chain of Thought: Let's think step by step.\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# 2. Call the generator with a sufficient max_length for the reasoning steps\n",
    "# We use 300 to ensure the model has enough tokens to write out all the steps.\n",
    "cot_result = generator(cot_prompt, max_length=300)\n",
    "\n",
    "# 3. Print the generated text cleanly\n",
    "print(cot_result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e39a72-bfd6-4094-be39-eea1672086ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
